{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git pull\n",
        "!pip install shap\n",
        "import os\n",
        "os.chdir(\"/content/Inflation_master_thesis/FEDFormer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYgQ3fEN7se5",
        "outputId": "05bf3e91-3434-44fd-bd68-602ede35f6d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ES00inuA7iMV"
      },
      "outputs": [],
      "source": [
        "from utils.tools import dotdict\n",
        "import torch\n",
        "from exp.exp_main import Exp_Main\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QfAIpX9-7iMW"
      },
      "outputs": [],
      "source": [
        "args = dotdict()\n",
        "\n",
        "args.model = 'FEDformer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
        "args.task_id = 'informer'\n",
        "args.is_training = 1\n",
        "args.version = 'Fourier'\n",
        "args.task = 'test'\n",
        "args.data = 'custom' # data\n",
        "args.root_path = './dataset/' # root path of data file\n",
        "args.data_path = 'Informer-data.csv' # data file\n",
        "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
        "args.target = 'Austria' # target feature in S or MS task\n",
        "args.continent = 'Europe'\n",
        "args.freq = 'm' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
        "args.detail_freq = args.freq\n",
        "args.freq = args.freq[-1:]\n",
        "args.checkpoints = './Autoformer_checkpoints' # location of model checkpoints\n",
        "\n",
        "args.mode_select = 'random'\n",
        "args.modes = 32\n",
        "args.seq_len = 32 # input sequence length of Informer encoder\n",
        "args.label_len = 16# start token length of Informer decoder\n",
        "args.pred_len = 12 # prediction sequence length\n",
        "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
        "\n",
        "args.enc_in = 97 # encoder input size\n",
        "args.dec_in = 97 # decoder input size\n",
        "args.c_out  = 97 # output size\n",
        "args.factor = 2 # probsparse attn factor\n",
        "args.d_model = 512 # dimension of model\n",
        "args.n_heads = 8 # num of heads\n",
        "args.e_layers = 2 # num of encoder layers\n",
        "args.d_layers = 2 # num of decoder layers\n",
        "args.d_ff = 2048 # dimension of fcn in model\n",
        "args.dropout = 0.1 # dropout\n",
        "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
        "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
        "args.activation = 'gelu' # activation\n",
        "args.distil = True # whether to use distilling in encoder\n",
        "args.output_attention = False # whether to output attention in ecoder\n",
        "args.mix = True\n",
        "args.padding = 0\n",
        "args.do_predict = True\n",
        "args.moving_avg = 12\n",
        "args.cross_activation = 'tanh'\n",
        "args.base = 'legendre'\n",
        "\n",
        "args.batch_size = 16\n",
        "args.learning_rate = 0.0001\n",
        "args.loss = 'mse'\n",
        "args.lradj = 'type1'\n",
        "args.use_amp = False # whether to use automatic mixed precision training\n",
        "\n",
        "args.num_workers = 0\n",
        "args.itr = 1\n",
        "args.train_epochs = 8\n",
        "args.patience = 3\n",
        "args.des = 'exp'\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() else False\n",
        "args.gpu = 0\n",
        "\n",
        "args.use_multi_gpu = False\n",
        "args.devices = '0,1,2,3'\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3812e48fa05140278d518f9cd50071e3",
            "6e2da1b43e754fb2908433ce763feff4",
            "263bfa0b34184db98d44efb401160279",
            "2202fee863fe4e33a347c38dea924d51",
            "05cd43f5fc40479d891ad92f334ba959",
            "76ff9904a2334bb89576a7df6f0a1b79",
            "fc3ea907370d4c95ae2e8f9c9f936a65",
            "ca2ac0888fdf4d70b18afa4a4a099a09",
            "207454979513488bb40f2994e182c83c",
            "b35e27288c02481fb6cd09ee3ca4dabc",
            "049db4cf1cdd414a92f652f438d76e39"
          ]
        },
        "id": "DPqDPB3I7iMZ",
        "outputId": "2bcdebdf-d35c-4106-9d6d-606ca0b12296"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/238 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3812e48fa05140278d518f9cd50071e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: cuda:0\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            ">>>>>>>start training : 000_Autoformer_h1_seqlen6_labellen6_heads8_encoderlayers2_dm512_ma5_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 199\n",
            "val 13\n",
            "test 0\n",
            "Epoch: 1 cost time: 1.0992863178253174\n",
            "Epoch: 1, Steps: 13 | Train Loss: 1.3225446 Vali Loss: 1.0632658 Test Loss: nan\n",
            "Validation loss decreased (inf --> 1.063266).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "Epoch: 2 cost time: 0.6110348701477051\n",
            "Epoch: 2, Steps: 13 | Train Loss: 1.1079895 Vali Loss: 0.9915426 Test Loss: nan\n",
            "Validation loss decreased (1.063266 --> 0.991543).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "Epoch: 3 cost time: 0.5690102577209473\n",
            "Epoch: 3, Steps: 13 | Train Loss: 0.9968145 Vali Loss: 0.9687145 Test Loss: nan\n",
            "Validation loss decreased (0.991543 --> 0.968714).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "Epoch: 4 cost time: 0.5800209045410156\n",
            "Epoch: 4, Steps: 13 | Train Loss: 0.9549685 Vali Loss: 0.9614130 Test Loss: nan\n",
            "Validation loss decreased (0.968714 --> 0.961413).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "Epoch: 5 cost time: 0.5748991966247559\n",
            "Epoch: 5, Steps: 13 | Train Loss: 0.9378567 Vali Loss: 0.9584196 Test Loss: nan\n",
            "Validation loss decreased (0.961413 --> 0.958420).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "Epoch: 6 cost time: 0.5631246566772461\n",
            "Epoch: 6, Steps: 13 | Train Loss: 0.9323603 Vali Loss: 0.9580717 Test Loss: nan\n",
            "Validation loss decreased (0.958420 --> 0.958072).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            "Epoch: 7 cost time: 0.5521888732910156\n",
            "Epoch: 7, Steps: 13 | Train Loss: 0.9258148 Vali Loss: 0.9561109 Test Loss: nan\n",
            "Validation loss decreased (0.958072 --> 0.956111).  Saving model ...\n",
            "Updating learning rate to 1.5625e-06\n",
            "Epoch: 8 cost time: 0.5745325088500977\n",
            "Epoch: 8, Steps: 13 | Train Loss: 0.9249657 Vali Loss: 0.9567208 Test Loss: nan\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 7.8125e-07\n",
            "val 13\n",
            "Validation Loss 0.9561108946800232, loss1 0.9561108946800232\n",
            "New best model with loss: 0.9561108946800232\n",
            "0.9561109\n",
            "{'model': 'Autoformer', 'task_id': 'Autoformer_h1', 'is_training': 1, 'version': 'Fourier', 'task': 'test', 'data': 'custom', 'root_path': './dataset/', 'data_path': 'Informer-data.csv', 'features': 'M', 'target': 'Austria', 'continent': 'Europe', 'freq': 'm', 'detail_freq': 'm', 'checkpoints': './Autoformer_checkpoints', 'mode_select': 'random', 'modes': 32, 'seq_len': 6, 'label_len': 6, 'pred_len': 12, 'enc_in': 97, 'dec_in': 97, 'c_out': 97, 'factor': 2, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.1, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'do_predict': True, 'moving_avg': 5, 'cross_activation': 'tanh', 'base': 'legendre', 'batch_size': 16, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 8, 'patience': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'idx': 0}\n",
            "000_Autoformer_h1_seqlen6_labellen6_heads8_encoderlayers2_dm512_ma5_0\n",
            ">>>>>>>start prediction_training : 000_Autoformer_h1_seqlen6_labellen6_heads8_encoderlayers2_dm512_ma5_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>predicting : 000_Autoformer_h1_seqlen6_labellen6_heads8_encoderlayers2_dm512_ma5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "pred 1\n",
            "Use GPU: cuda:0\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            "Autocorrelation used !\n",
            ">>>>>>>start training : 001_Autoformer_h1_seqlen6_labellen6_heads8_encoderlayers2_dm512_ma5_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 199\n",
            "val 13\n",
            "test 0\n",
            "Epoch: 1 cost time: 0.5748424530029297\n",
            "Epoch: 1, Steps: 13 | Train Loss: 1.3298184 Vali Loss: 1.0638463 Test Loss: nan\n",
            "Validation loss decreased (inf --> 1.063846).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "Epoch: 2 cost time: 0.5485861301422119\n",
            "Epoch: 2, Steps: 13 | Train Loss: 1.1150341 Vali Loss: 0.9829692 Test Loss: nan\n",
            "Validation loss decreased (1.063846 --> 0.982969).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "Epoch: 3 cost time: 0.5509810447692871\n",
            "Epoch: 3, Steps: 13 | Train Loss: 1.0097882 Vali Loss: 0.9625663 Test Loss: nan\n",
            "Validation loss decreased (0.982969 --> 0.962566).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "Epoch: 4 cost time: 0.5363290309906006\n",
            "Epoch: 4, Steps: 13 | Train Loss: 0.9771878 Vali Loss: 0.9552128 Test Loss: nan\n",
            "Validation loss decreased (0.962566 --> 0.955213).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "Epoch: 5 cost time: 0.5441877841949463\n",
            "Epoch: 5, Steps: 13 | Train Loss: 0.9526642 Vali Loss: 0.9519327 Test Loss: nan\n",
            "Validation loss decreased (0.955213 --> 0.951933).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "Epoch: 6 cost time: 0.530670166015625\n",
            "Epoch: 6, Steps: 13 | Train Loss: 0.9471891 Vali Loss: 0.9507626 Test Loss: nan\n",
            "Validation loss decreased (0.951933 --> 0.950763).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            "Epoch: 7 cost time: 0.5426113605499268\n",
            "Epoch: 7, Steps: 13 | Train Loss: 0.9367754 Vali Loss: 0.9494766 Test Loss: nan\n",
            "Validation loss decreased (0.950763 --> 0.949477).  Saving model ...\n",
            "Updating learning rate to 1.5625e-06\n",
            "Epoch: 8 cost time: 0.5462658405303955\n",
            "Epoch: 8, Steps: 13 | Train Loss: 0.9346571 Vali Loss: 0.9480321 Test Loss: nan\n",
            "Validation loss decreased (0.949477 --> 0.948032).  Saving model ...\n",
            "Updating learning rate to 7.8125e-07\n",
            "val 13\n",
            "Validation Loss 0.9480320811271667, loss1 0.9480320811271667\n",
            "New best model with loss: 0.9480320811271667\n",
            "0.9480321\n",
            "{'model': 'Autoformer', 'task_id': 'Autoformer_h1', 'is_training': 1, 'version': 'Fourier', 'task': 'test', 'data': 'custom', 'root_path': './dataset/', 'data_path': 'Informer-data.csv', 'features': 'M', 'target': 'Austria', 'continent': 'Europe', 'freq': 'm', 'detail_freq': 'm', 'checkpoints': './Autoformer_checkpoints', 'mode_select': 'random', 'modes': 32, 'seq_len': 6, 'label_len': 6, 'pred_len': 12, 'enc_in': 97, 'dec_in': 97, 'c_out': 97, 'factor': 2, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.1, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'do_predict': True, 'moving_avg': 5, 'cross_activation': 'tanh', 'base': 'legendre', 'batch_size': 16, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 8, 'patience': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'idx': 1}\n",
            "001_Autoformer_h1_seqlen6_labellen6_heads8_encoderlayers2_dm512_ma5_0\n",
            ">>>>>>>start prediction_training : 001_Autoformer_h1_seqlen6_labellen6_heads8_encoderlayers2_dm512_ma5_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>predicting : 001_Autoformer_h1_seqlen6_labellen6_heads8_encoderlayers2_dm512_ma5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "pred 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-2323087799.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_setting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/content/Inflation_master_thesis/FEDFormer/Autoformer_checkpoints\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf'/content/Inflation_master_thesis/FEDFormer/Autoformer_checkpoints/{ckpt}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Inflation_master_thesis/FEDFormer/exp/exp_main.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, setting, load)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/__init__.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_additivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_pytorch.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;31m# run attribution computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0msample_phis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 \u001b[0;31m# assign the attributions to the right part of the output arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_pytorch.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, idx, inputs)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 grad = torch.autograd.grad(\n\u001b[0m\u001b[1;32m    121\u001b[0m                     \u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_unused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 )[0]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n\u001b[1;32m    495\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         result = _engine_run_backward(\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Exp = Exp_Main\n",
        "seq_lengths = [6]#, 12, 24, 48]\n",
        "\n",
        "args.task_id = \"Autoformer_h1\"\n",
        "\n",
        "if args.is_training:\n",
        "    for m in ['Autoformer']:\n",
        "        args.model = m\n",
        "        for i in tqdm(range(0, 238)):\n",
        "            best_loss = float('inf')\n",
        "            for kernel_size in [5]:#, 9, 13, 25]:\n",
        "                args.moving_avg = kernel_size\n",
        "                for idx, seq_length in enumerate(seq_lengths):\n",
        "                    args.seq_len = seq_length\n",
        "                    for label_length in seq_lengths[:idx + 1]:\n",
        "                        args.label_len = label_length\n",
        "                        # Set augments by using data name\n",
        "                        args.idx = i\n",
        "                        j = str(i)\n",
        "                        while(len(j)<3):\n",
        "                            j = '0' + j\n",
        "                        for ii in range(args.itr):\n",
        "                            # setting record of experiments\n",
        "                            setting = '{}_{}_seqlen{}_labellen{}_heads{}_encoderlayers{}_dm{}_ma{}_{}'.format(\n",
        "                                j,\n",
        "                                args.task_id,\n",
        "                                args.seq_len,\n",
        "                                args.label_len,\n",
        "                                args.n_heads,\n",
        "                                args.e_layers,\n",
        "                                args.d_model,\n",
        "                                args.moving_avg,\n",
        "                                ii)\n",
        "\n",
        "                            exp = Exp(args)  # set experiments\n",
        "                            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "                            try:\n",
        "                                exp.train(setting)\n",
        "                            except Exception as e:\n",
        "                                print(f\"===========================GOT ERROR: {e}\")\n",
        "                                continue\n",
        "                            vali_data, vali_loader = exp._get_data(flag='val')\n",
        "                            loss = exp.vali(vali_data, vali_loader, exp._select_criterion())\n",
        "                            loss1 = exp.vali(vali_data, vali_loader, exp._select_criterion())\n",
        "                            print(f\"Validation Loss {loss}, loss1 {loss1}\")\n",
        "                            torch.cuda.empty_cache()\n",
        "                            if loss < best_loss:\n",
        "                                print(f\"New best model with loss: {loss}\")\n",
        "                                best_loss = loss\n",
        "                                best_args = args\n",
        "                                best_setting = setting\n",
        "                            print(best_loss)\n",
        "                            print(best_args)\n",
        "                            print(best_setting)\n",
        "\n",
        "            if args.do_predict:\n",
        "                #exp = Exp(best_args)  # set experiments\n",
        "                print('>>>>>>>start prediction_training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(best_setting))\n",
        "                #exp.train(best_setting)\n",
        "                print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(best_setting))\n",
        "                exp.predict(best_setting, True)\n",
        "                for ckpt in os.listdir(r\"/content/Inflation_master_thesis/FEDFormer/Autoformer_checkpoints\"):\n",
        "                    shutil.rmtree(rf'/content/Inflation_master_thesis/FEDFormer/Autoformer_checkpoints/{ckpt}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrUptZj17iMa"
      },
      "outputs": [],
      "source": [
        "Exp = Exp_Main\n",
        "seq_lengths = [6, 12, 24, 48]\n",
        "\n",
        "args.task_id = \"Autoformer_h6\"\n",
        "args.pred_len = 6\n",
        "\n",
        "if args.is_training:\n",
        "    for m in ['Autoformer']:\n",
        "        args.model = m\n",
        "        for i in tqdm(range(0, 238)):\n",
        "            best_loss = float('inf')\n",
        "            for kernel_size in [5, 9, 13, 25]:\n",
        "                args.moving_avg = kernel_size\n",
        "                for idx, seq_length in enumerate(seq_lengths):\n",
        "                    args.seq_len = seq_length\n",
        "                    for label_length in seq_lengths[:idx + 1]:\n",
        "                        args.label_len = label_length\n",
        "                        # Set augments by using data name\n",
        "                        args.idx = i\n",
        "                        j = str(i)\n",
        "                        while(len(j)<3):\n",
        "                            j = '0' + j\n",
        "                        for ii in range(args.itr):\n",
        "                            # setting record of experiments\n",
        "                            setting = '{}_{}_seqlen{}_labellen{}_heads{}_encoderlayers{}_model{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}__ma{}_{}'.format(\n",
        "                                j,\n",
        "                                args.task_id,\n",
        "                                args.seq_len,\n",
        "                                args.label_len,\n",
        "                                args.n_heads,\n",
        "                                args.e_layers,\n",
        "                                args.model,\n",
        "                                args.batch_size,\n",
        "                                args.mode_select,\n",
        "                                args.modes,\n",
        "                                args.data,\n",
        "                                args.features,\n",
        "                                args.pred_len,\n",
        "                                args.d_model,\n",
        "                                args.d_layers,\n",
        "                                args.d_ff,\n",
        "                                args.factor,\n",
        "                                args.embed,\n",
        "                                args.distil,\n",
        "                                args.des,\n",
        "                                args.moving_avg,\n",
        "                                ii)\n",
        "\n",
        "                            exp = Exp(args)  # set experiments\n",
        "                            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "                            try:\n",
        "                                exp.train(setting)\n",
        "                            except Exception as e:\n",
        "                                print(f\"===========================GOT ERROR: {e}\")\n",
        "                                continue\n",
        "                            vali_data, vali_loader = exp._get_data(flag='val')\n",
        "                            loss = exp.vali(vali_data, vali_loader, exp._select_criterion())\n",
        "                            torch.cuda.empty_cache()\n",
        "                            if loss < best_loss:\n",
        "                                print(f\"New best model with loss: {loss}\")\n",
        "                                best_loss = loss\n",
        "                                best_args = args\n",
        "                                best_setting = setting\n",
        "                            print(best_loss)\n",
        "                            print(best_args)\n",
        "                            print(best_setting)\n",
        "\n",
        "            if args.do_predict:\n",
        "                #exp = Exp(best_args)  # set experiments\n",
        "                print('>>>>>>>start prediction_training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(best_setting))\n",
        "                #exp.train(best_setting)\n",
        "                print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(best_setting))\n",
        "                exp.predict(best_setting, True)\n",
        "                for ckpt in os.listdir(\"C:/Users/osahl/Desktop/UNI/master thesis/FEDFormer/Autoformer_checkpoints\"):\n",
        "                    shutil.rmtree(f'C:/Users/osahl/Desktop/UNI/master thesis/FEDFormer/Autoformer_checkpoints/{ckpt}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlp9d0ER7iMb"
      },
      "outputs": [],
      "source": [
        "Exp = Exp_Main\n",
        "seq_lengths = [6, 12, 24, 48]\n",
        "\n",
        "args.task_id = \"Autoformer_h12\"\n",
        "args.pred_len = 12\n",
        "\n",
        "if args.is_training:\n",
        "    for m in ['Autoformer']:\n",
        "        args.model = m\n",
        "        for i in tqdm(range(0, 238)):\n",
        "            best_loss = float('inf')\n",
        "            for kernel_size in [5, 9, 13, 25]:\n",
        "                args.moving_avg = kernel_size\n",
        "                for idx, seq_length in enumerate(seq_lengths):\n",
        "                    args.seq_len = seq_length\n",
        "                    for label_length in seq_lengths[:idx + 1]:\n",
        "                        args.label_len = label_length\n",
        "                        # Set augments by using data name\n",
        "                        args.idx = i\n",
        "                        j = str(i)\n",
        "                        while(len(j)<3):\n",
        "                            j = '0' + j\n",
        "                        for ii in range(args.itr):\n",
        "                            # setting record of experiments\n",
        "                            setting = '{}_{}_seqlen{}_labellen{}_heads{}_encoderlayers{}_model{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}__ma{}_{}'.format(\n",
        "                                j,\n",
        "                                args.task_id,\n",
        "                                args.seq_len,\n",
        "                                args.label_len,\n",
        "                                args.n_heads,\n",
        "                                args.e_layers,\n",
        "                                args.model,\n",
        "                                args.batch_size,\n",
        "                                args.mode_select,\n",
        "                                args.modes,\n",
        "                                args.data,\n",
        "                                args.features,\n",
        "                                args.pred_len,\n",
        "                                args.d_model,\n",
        "                                args.d_layers,\n",
        "                                args.d_ff,\n",
        "                                args.factor,\n",
        "                                args.embed,\n",
        "                                args.distil,\n",
        "                                args.des,\n",
        "                                args.moving_avg,\n",
        "                                ii)\n",
        "\n",
        "                            exp = Exp(args)  # set experiments\n",
        "                            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "                            try:\n",
        "                                exp.train(setting)\n",
        "                            except Exception as e:\n",
        "                                print(f\"===========================GOT ERROR: {e}\")\n",
        "                                continue\n",
        "                            vali_data, vali_loader = exp._get_data(flag='val')\n",
        "                            loss = exp.vali(vali_data, vali_loader, exp._select_criterion())\n",
        "                            torch.cuda.empty_cache()\n",
        "                            if loss < best_loss:\n",
        "                                print(f\"New best model with loss: {loss}\")\n",
        "                                best_loss = loss\n",
        "                                best_args = args\n",
        "                                best_setting = setting\n",
        "                            print(best_loss)\n",
        "                            print(best_args)\n",
        "                            print(best_setting)\n",
        "\n",
        "            if args.do_predict:\n",
        "                #exp = Exp(best_args)  # set experiments\n",
        "                print('>>>>>>>start prediction_training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(best_setting))\n",
        "                #exp.train(best_setting)\n",
        "                print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(best_setting))\n",
        "                exp.predict(best_setting, True)\n",
        "                for ckpt in os.listdir(\"C:/Users/osahl/Desktop/UNI/master thesis/FEDFormer/Autoformer_checkpoints\"):\n",
        "                    shutil.rmtree(f'C:/Users/osahl/Desktop/UNI/master thesis/FEDFormer/Autoformer_checkpoints/{ckpt}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS-Qr-xf7iMc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3812e48fa05140278d518f9cd50071e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e2da1b43e754fb2908433ce763feff4",
              "IPY_MODEL_263bfa0b34184db98d44efb401160279",
              "IPY_MODEL_2202fee863fe4e33a347c38dea924d51"
            ],
            "layout": "IPY_MODEL_05cd43f5fc40479d891ad92f334ba959"
          }
        },
        "6e2da1b43e754fb2908433ce763feff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ff9904a2334bb89576a7df6f0a1b79",
            "placeholder": "​",
            "style": "IPY_MODEL_fc3ea907370d4c95ae2e8f9c9f936a65",
            "value": "  0%"
          }
        },
        "263bfa0b34184db98d44efb401160279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca2ac0888fdf4d70b18afa4a4a099a09",
            "max": 238,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_207454979513488bb40f2994e182c83c",
            "value": 1
          }
        },
        "2202fee863fe4e33a347c38dea924d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35e27288c02481fb6cd09ee3ca4dabc",
            "placeholder": "​",
            "style": "IPY_MODEL_049db4cf1cdd414a92f652f438d76e39",
            "value": " 1/238 [01:38&lt;4:10:19, 63.37s/it]"
          }
        },
        "05cd43f5fc40479d891ad92f334ba959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ff9904a2334bb89576a7df6f0a1b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3ea907370d4c95ae2e8f9c9f936a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca2ac0888fdf4d70b18afa4a4a099a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "207454979513488bb40f2994e182c83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b35e27288c02481fb6cd09ee3ca4dabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "049db4cf1cdd414a92f652f438d76e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}